<!DOCTYPE html>
<html>

<head>
    <title>Project 5</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
    </style>
    <meta charset="UTF-8">
    <title id="cs180-title">CS 180 - Project 5</title>
    <link rel="stylesheet" href="style.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>


<body>
    <section id="header">
        <div class="container">
            <h1>CS 180 Project 5</h1>
            <h2>Diffusion Models</h2>
            <p> by Ziran Zhou</p>
        </div>
    </section>

    <section id="overview">
        <div class="container">
            <h1>Overview</h1>
            <p>In this project, I followed the instructions and the background introduction
                of the spec and explored how to use diffusion models to operate on and generate various images, and also
                implemented the models myself. </p>
        </div>
    </section>

    <section id="implementation">
        <div class="container">
            <h1>Part A: The Power of Diffusion Models!</h1>
            <div>
                <p>
                    This first part I worked with DeepFloyd IF Difussion model to implement difussion sampling
                    iteratively and used it for impainting and optical illusion generation.
                </p>
            </div>
            <h2>Part 0 - Set Up</h2>
            <div>
                <p>
                    To start, set up the pretrained model (DeepFloyd) as a two stage difussion model with teh 1st stage
                    creating 64x64 image and 2nd 256x256 with pixels as units, indicating the subsequent image quality
                    difference. Then, model can be sampled with different number of inference steps where it determines
                    the number of denoising steps to take, i.e., th ehigher the inference step, the higher image
                    quality.
                </p>
                <p>
                    Below are some images generated by stage 1 and stage 2 at 20 inference stpes, and we can see the
                    quality and size difference between the stages, but also with a limited inference step, the
                    complexity of the result is low.
                </p>
                <p>
                    Generated Images with Stage 1 Inference 20:
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/im1.png" alt="im1" class="fixed-size-image">
                    </div>
                    <div class="image">
                        <img src="media/im2.png" alt="im2" class="fixed-size-image">
                    </div>
                    <div class="image">
                        <img src="media/im3.png" alt="im3" class="fixed-size-image">
                    </div>
                </div>

                <p>
                    Generated Images with Stage 2 Inference 20:
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/im1*.png" alt="im1 stage 2" class="fixed-size-image">
                    </div>
                    <div class="image">
                        <img src="media/im2*.png" alt="im2 stage 2" class="fixed-size-image">
                    </div>
                    <div class="image">
                        <img src="media/im3*.png" alt="im3 stage 2" class="fixed-size-image">
                    </div>
                </div>
                <p>
                    Below I generated of the same prompt over both stages but with inference step of 100, and we can
                    clearly see they are much more detailed.
                </p>

                <p>
                    Generated Images with Stage 1 Inference 100:
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/im1-100.png" alt="im1 100" class="fixed-size-image">
                    </div>
                    <div class="image">
                        <img src="media/im2-100.png" alt="im2 100" class="fixed-size-image">
                    </div>
                    <div class="image">
                        <img src="media/im3-100.png" alt="im3 100" class="fixed-size-image">
                    </div>
                </div>

                <p>
                    Generated Images with Stage 2 Inference 100:
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/im1-100*.png" alt="im1 stage 2 100" class="fixed-size-image">
                    </div>
                    <div class="image">
                        <img src="media/im2-100*.png" alt="im2 stage 2 100" class="fixed-size-image">
                    </div>
                    <div class="image">
                        <img src="media/im3-100*.png" alt="im3 stage 2 100" class="fixed-size-image">
                    </div>
                </div>
            </div>
            <h2>Part 1 - Sampling Loops</h2>
            <h3>Step 1.1 - Implementing the Forward Process</h3>
            <p>
                Here, I use the pretrained DeepFloyd denoisers to operate on a clean image \(x_0\) then iteratively add
                noise, by the amount determined by coefficient \(\alpha_t\) and \(T=1000\), to it to get a image of pure
                noise \(x_t\). Then use a diffusion model to reverse the process by predicting the noise and denoising
                the image, i.e., given \(x_t\) we predict the noise and remove it from it, and iteratively, we hope to
                get something resembling of the original input clean image \(x_0\).
            </p>
            <div>
                <p>
                    We sample the noise from the distribution \(q(x_t|x_0) = N(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 -
                    \bar{\alpha}_t)I)\), which is equivalent to computing \(x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 -
                    \bar{\alpha}_t} \epsilon \quad \text{where} \quad
                    \epsilon \sim N(0, 1)\).
                </p>
                <p>
                    Below are noisy images generated under various values of \(t\).
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/clean.png" alt="clean campanile" class="small-im">
                        <p>
                            Original Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-1.png" alt="noisy campanile 1" class="small-im">
                        <p>
                            Noisy Image when \(t\)=250
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-2.png" alt="noisy campanile 2" class="small-im">
                        <p>
                            Noisy Image when \(t\)=500
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-3.png" alt="noisy campanile 3" class="small-im">
                        <p>
                            Noisy Image when \(t\)=750
                        </p>
                    </div>
                </div>
            </div>

            <h3>Step 1.2 - Classical Denoising</h3>
            <div>
                <p>
                    I applied Gaussian Blur Filter (kernel size of 7 and sigma of 2) to the noisy images generated in
                    the previous part as the conventional denoising approach and the results are shown below:
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/noisy-1.png" alt="noisy campanile 1" class="small-im">
                        <p>
                            Noisy Image when \(t\)=250
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/gausblur-1.png" alt="gaussian blurred campanile 1" class="small-im">
                        <p>
                            Gaussian Blurred Image when \(t\)=250
                        </p>
                    </div>
                </div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/noisy-2.png" alt="noisy campanile 2" class="small-im">
                        <p>
                            Noisy Image when \(t\)=500
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/gausblur-2.png" alt="gaussian blurred campanile 2" class="small-im">
                        <p>
                            Gaussian Blurred Image when \(t\)=500
                        </p>
                    </div>
                </div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/noisy-3.png" alt="noisy campanile 3" class="small-im">
                        <p>
                            Noisy Image when \(t\)=750
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/gausblur-3.png" alt="gaussian blurred campanile 3" class="small-im">
                        <p>
                            Gaussian Blurred Image when \(t\)=750
                        </p>
                    </div>
                </div>
                <p>
                    The results look like they are just blending the noises into smoother versions instead of
                    removing them, which is why conventional Gaussian Blurring approach is not the most effective
                    one.
                </p>
            </div>
            <p>
                .
            </p>
            <h3>Step 1.3 - One-Step Denoising</h3>
            <div>
                <p>
                    Per the instructions, I then used a pretrained UNet denoiser of DeepFloyd to estimate the Gaussian
                    noise from the image given a timestep \(t\) and at each step, remove the noise from the image, till
                    we eventually arrive at an image resembling the original image, though some difference is expected
                    due to the noise estimations is not perfectly accurate. The model is needs a prompt and we input "a
                    high quality photo" to train it with text conditions.
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/noisy-1.png" alt="noisy campanile 1" class="small-im">
                        <p>
                            Noisy Image when \(t\)=250
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/denoised-1.png" alt="one-step denoised campanile 1" class="small-im">
                        <p>
                            One-Step Denoised Image when \(t\)=250
                        </p>
                    </div>
                </div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/noisy-2.png" alt="noisy campanile 2" class="small-im">
                        <p>
                            Noisy Image when \(t\)=500
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/denoised-2.png" alt="one-step denoised campanile 2" class="small-im">
                        <p>
                            One-Step Denoised Image when \(t\)=500
                        </p>
                    </div>
                </div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/noisy-3.png" alt="noisy campanile 3" class="small-im">
                        <p>
                            Noisy Image when \(t\)=750
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/denoised-3.png" alt="one-step denoised campanile 3" class="small-im">
                        <p>
                            One-Step Denoised Image when \(t\)=750
                        </p>
                    </div>
                </div>
                <p>
                    The results are much better than teh previous conventional Gaussian Blur denoising, though the
                    more the noises in the input image, the more different from teh original the denoised result is.
                </p>
                <p>
                    Below is a line up of all the results from before.
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/clean.png" alt="clean campanile" class="small-im">
                        <p>
                            Original Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-1.png" alt="noisy campanile 1" class="small-im">
                        <p>
                            Noisy Image when \(t\)=250
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/gausblur-1.png" alt="gaussian blurred campanile 1" class="small-im">
                        <p>
                            Gaussian Blurred Image when \(t\)=250
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/denoised-1.png" alt="one-step denoised campanile 1" class="small-im">
                        <p>
                            One-Step Denoised Image when \(t\)=250
                        </p>
                    </div>
                </div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/clean.png" alt="clean campanile" class="small-im">
                        <p>
                            Original Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-2.png" alt="noisy campanile 2" class="small-im">
                        <p>
                            Noisy Image when \(t\)=500
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/gausblur-2.png" alt="gaussian blurred campanile 1" class="small-im">
                        <p>
                            Gaussian Blurred Image when \(t\)=250
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/denoised-2.png" alt="one-step denoised campanile 2" class="small-im">
                        <p>
                            One-Step Denoised Image when \(t\)=500
                        </p>
                    </div>
                </div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/clean.png" alt="clean campanile" class="small-im">
                        <p>
                            Original Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-3.png" alt="noisy campanile 2" class="small-im">
                        <p>
                            Noisy Image when \(t\)=750
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/gausblur-3.png" alt="gaussian blurred campanile 1" class="small-im">
                        <p>
                            Gaussian Blurred Image when \(t\)=750
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/denoised-3.png" alt="one-step denoised campanile 2" class="small-im">
                        <p>
                            One-Step Denoised Image when \(t\)=750
                        </p>
                    </div>
                </div>
            </div>

            <h3>Step 1.4 - Iterative Denoising</h3>
            <div>
                <p>
                    To improve the denoising through difussino model, I followed the instruction to train the models to
                    denoise iteratively over numerous steps, and iteratively denoise one step at a time till timestep of
                    \(T=1000\), but since it is too computationally costly, I skipped steps and use strided timesteps
                    starting at \(t=990\) (or \(t=999\)) and taking strides of 30 timesteps per step till \(t=0\) when
                    we arrive at the clean image denoised result. The other parameters are defined as required on the
                    spec website.
                </p>
                <p>
                    We also assign the next-step denoised image \(x_{t'}\) at timestep \(t'\) using the previous-step
                    denoised image \(x_t\) through the following formula
                    defines: \[x_{t'} = \frac{\sqrt{\bar{\alpha}_{t'} \beta_t} x_0 + \sqrt{\alpha_t (1 -
                    \bar{\alpha}_{t'})}x_t}{1- \bar{\alpha}_t} + v_{\sigma}\]
                </p>
                <p>
                    Below are the resulting images of the purely noisy image iteratively being denoised from timestep of
                    990, also the iteratively-denoised image result compard with previous parts's images.
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/noisy-t-30.png" alt="noisy-t-30" class="small-im">
                        <p>
                            \(t=30\)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-t-90.png" alt="noisy-t-90" class="small-im">
                        <p>
                            \(t=90\)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-t-240.png" alt="noisy-t-240" class="small-im">
                        <p>
                            \(t=240\)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-t-390.png" alt="noisy-t-390" class="small-im">
                        <p>
                            \(t=390\)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-t-540.png" alt="noisy-t-540" class="small-im">
                        <p>
                            \(t=540\)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/noisy-t-690.png" alt="noisy-t-690" class="small-im">
                        <p>
                            \(t=690\)
                        </p>
                    </div>
                </div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/clean.png" alt="clean original image" class="small-im">
                        <p>
                            Original Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/iter-denoised.png" alt="iteratively-denoised image" class="small-im">
                        <p>
                            Iteratively Denoised Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/1step-denoised.png" alt="one-step-denoised image" class="small-im">
                        <p>
                            One-Step Denoised Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/gausblur-denoised.png" alt="gaussian-blurred-denoised image" class="small-im">
                        <p>
                            Gaussian Blurred Denoised Image
                        </p>
                    </div>
                </div>
                <p>
                    We see that the Iteratively Denoised image is much more detailed than the One-Step Denoised image,
                    and resembles the original image more in terms of structure and also pixel details, indicating that
                    the iteratively denoising process restores more detail during denoising.
                </p>
            </div>

            <p>.
            </p>

            <h3>Step 1.5 - Diffusion Model Sampling</h3>
            <div>
                <p>
                    Unlike previous part, here i start with pure random noise to let the model denoise it and generate
                    image from scratch, and the results are shown below:
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/a.5-1.png" alt="pure noise generated image 1" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/a.5-2.png" alt="pure noise generated image 2" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/a.5-3.png" alt="pure noise generated image 3" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/a.5-4.png" alt="pure noise generated image 4" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/a.5-5.png" alt="pure noise generated image 5" class="small-im">
                    </div>
                </div>
                <p>
                    The images generated have rather poor quality, though does resemble some realistic image we would
                    have seen in real life.
                </p>
            </div>
            <p>.
            </p>

            <h3>Step 1.6 - Classifier-Free Guidance (CFG)</h3>
            <div>
                <p>
                    Classifier-Free Guidance denoising is implemented in this subpart. I compute the conditional noise
                    estimate \(\epsilon_c\) (with prompt as usual, "a high quality photo") and unconditional noise
                    estimate \(\epsilon_u\) (with prompt ""), tehn generating new noise would become \(\epsilon =
                    \epsilon_u + \gamma(\epsilon_c - \epsilon_u)\).
                </p>
                <p>
                    The CFG-generated sample results are shown below. They look to be more vibrant and seem to present
                    more details than the previous part, also resemble something real-life image.
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/cfg-1.png" alt="CFG generated image 1" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/cfg-2.png" alt="CFG generated image 2" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/cfg-3.png" alt="CFG generated image 3" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/cfg-4.png" alt="CFG generated image 4" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/cfg-5.png" alt="CFG generated image 5" class="small-im">
                    </div>
                </div>
            </div>

            <h3>Step 1.7 - Image-to-Image Translation</h3>
            <div>
                <p>
                    Apply SDEdit algorithm by mapping and adding noises to an image and force it back to the image
                    manifold but do not do any conditioning. The parameter <code>i_start</code> is used to indicate the
                    number of iterative denoising steps away from the starting pure noise image for the denoising
                    process to begin, and since we are subtracting noises from noisy images incrementally across the
                    strided steps, starting from the noisy image (in this case that of the <code>test_im</code>), and
                    <code>i_start</code> determines how far into the denoising increment to begin the Iterative
                    Denoising process.
                </p>
                <p>
                    Thus, smaller values of <code>i_start</code> mean the closer to \(T=1000\), i.e., more noises in the
                    input to start iterative denoising, and vice versa.
                </p>
                <p>
                    Set the <code>i_start</code> values as [1, 3, 5, 7, 10, 20], then produce the results as shown
                    below:
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/SDEdit-1.png" alt="SDEdit with i_start=1" class="small-im">
                        <p>
                            SDEdit (<code>i_start=1</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/SDEdit-3.png" alt="SDEdit with i_start=3" class="small-im">
                        <p>
                            SDEdit (<code>i_start=3</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/SDEdit-5.png" alt="SDEdit with i_start=5" class="small-im">
                        <p>
                            SDEdit (<code>i_start=5</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/SDEdit-7.png" alt="SDEdit with i_start=7" class="small-im">
                        <p>
                            SDEdit (<code>i_start=7</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/SDEdit-10.png" alt="SDEdit with i_start=10" class="small-im">
                        <p>
                            SDEdit (<code>i_start=10</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/SDEdit-20.png" alt="SDEdit with i_start=20" class="small-im">
                        <p>
                            SDEdit (<code>i_start=20</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/clean.png" alt="clean original image" class="small-im">
                        <p>
                            Campanile Clean Image
                        </p>
                    </div>
                </div>

                <div class="gallery-row">
                    <div class="image">
                        <img src="media/sf-1.png" alt="SDEdit of SF image with i_start=1" class="small-im">
                        <p>
                            SDEdit (<code>i_start=1</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf-3.png" alt="SDEdit of SF image with i_start=3" class="small-im">
                        <p>
                            SDEdit (<code>i_start=3</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf-5.png" alt="SDEdit of SF image with i_start=5" class="small-im">
                        <p>
                            SDEdit (<code>i_start=5</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf-7.png" alt="SDEdit of SF image with i_start=7" class="small-im">
                        <p>
                            SDEdit (<code>i_start=7</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf-10.png" alt="SDEdit of SF image with i_start=10" class="small-im">
                        <p>
                            SDEdit (<code>i_start=10</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf-20.png" alt="SDEdit of SF image with i_start=20" class="small-im">
                        <p>
                            SDEdit (<code>i_start=20</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf*.png" alt="clean original image" class="small-im">
                        <p>
                            San Francisco Sunset Clean Image
                        </p>
                    </div>
                </div>

                <div class="gallery-row">
                    <div class="image">
                        <img src="media/deer-1.png" alt="SDEdit of Deer Image with i_start=1" class="small-im">
                        <p>
                            SDEdit (<code>i_start=1</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/deer-3.png" alt="SDEdit of Deer Image with i_start=3" class="small-im">
                        <p>
                            SDEdit (<code>i_start=3</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/deer-5.png" alt="SDEdit of Deer Image with i_start=5" class="small-im">
                        <p>
                            SDEdit (<code>i_start=5</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/deer-7.png" alt="SDEdit of Deer Image with i_start=7" class="small-im">
                        <p>
                            SDEdit (<code>i_start=7</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/deer-10.png" alt="SDEdit of Deer Image with i_start=10" class="small-im">
                        <p>
                            SDEdit (<code>i_start=10</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/deer-20.png" alt="SDEdit of Deer Image with i_start=20" class="small-im">
                        <p>
                            SDEdit (<code>i_start=20</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/deer*.png" alt="clean original image" class="small-im">
                        <p>
                            Deer Clean Image
                        </p>
                    </div>
                </div>
                <p>
                    We can see from these 3 examples, that the SDEdit approach works well in generating various degrees
                    of restoration from pure noise.
                </p>
            </div>

            <h4>Step 1.7.1 - Editing Hand-Drawn and Web Images</h4>
            <div>
                <p>
                    I also implemented SDEdit on Web Image (<a
                        href="https://upload.wikimedia.org/wikipedia/en/3/35/Dune_2021-Sandworm.jpg">Shai-Hulud</a>),
                    and it is apparent that it work well, especially when it is close to the original image, i.e., large
                    <code>i_start</code> value.
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/dune-1.png" alt="SDEdit of Dune Image with i_start=1" class="small-im">
                        <p>
                            SDEdit (<code>i_start=1</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dune-3.png" alt="SDEdit of Dune Image with i_start=3" class="small-im">
                        <p>
                            SDEdit (<code>i_start=3</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dune-5.png" alt="SDEdit of Dune Image with i_start=5" class="small-im">
                        <p>
                            SDEdit (<code>i_start=5</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dune-7.png" alt="SDEdit of Dune Image with i_start=7" class="small-im">
                        <p>
                            SDEdit (<code>i_start=7</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dune-10.png" alt="SDEdit of Dune Image with i_start=10" class="small-im">
                        <p>
                            SDEdit (<code>i_start=10</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dune-20.png" alt="SDEdit of Dune Image with i_start=20" class="small-im">
                        <p>
                            SDEdit (<code>i_start=20</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dune-orig.png" alt="clean original image" class="small-im">
                        <p>
                            Dune Shai-Hulud Clean Image
                        </p>
                    </div>
                </div>

                <p>
                    I also implemented SDEdit on the hand-drawn images of a Waxing Moon with Clouds, and Several Palm
                    Trees and Hollywood Sign. As shown below.
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/hd-1.png" alt="SDEdit of Hand Drawn Moon Image with i_start=1" class="small-im">
                        <p>
                            SDEdit (<code>i_start=1</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hd-3.png" alt="SDEdit of Hand Drawn Moon Image with i_start=3" class="small-im">
                        <p>
                            SDEdit (<code>i_start=3</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hd-5.png" alt="SDEdit of Hand Drawn Moon Image with i_start=5" class="small-im">
                        <p>
                            SDEdit (<code>i_start=5</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hd-7.png" alt="SDEdit of Hand Drawn Moon Image with i_start=7" class="small-im">
                        <p>
                            SDEdit (<code>i_start=7</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hd-10.png" alt="SDEdit of Hand Drawn Moon Image with i_start=10"
                            class="small-im">
                        <p>
                            SDEdit (<code>i_start=10</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hd-20.png" alt="SDEdit of Hand Drawn Moon Image with i_start=20"
                            class="small-im">
                        <p>
                            SDEdit (<code>i_start=20</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/myImage.png" alt="clean original image" class="small-im">
                        <p>
                            Hand Drawn Moon Image
                        </p>
                    </div>
                </div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/hs-1.png" alt="SDEdit of Hand Drawn Hollywood Sign Image with i_start=1"
                            class="small-im">
                        <p>
                            SDEdit (<code>i_start=1</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hs-3.png" alt="SDEdit of Hand Drawn Hollywood Sign Image with i_start=3"
                            class="small-im">
                        <p>
                            SDEdit (<code>i_start=3</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hs-5.png" alt="SDEdit of Hand Drawn Hollywood Sign Image with i_start=5"
                            class="small-im">
                        <p>
                            SDEdit (<code>i_start=5</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hs-7.png" alt="SDEdit of Hand Drawn Hollywood Sign Image with i_start=7"
                            class="small-im">
                        <p>
                            SDEdit (<code>i_start=7</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hs-10.png" alt="SDEdit of Hand Drawn Hollywood Sign Image with i_start=10"
                            class="small-im">
                        <p>
                            SDEdit (<code>i_start=10</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/hs-20.png" alt="SDEdit of Hand Drawn Hollywood Sign Image with i_start=20"
                            class="small-im">
                        <p>
                            SDEdit (<code>i_start=20</code>)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/myImage_2.png" alt="clean original image" class="small-im">
                        <p>
                            Hand Drawn Hollywood Image
                        </p>
                    </div>
                </div>
            </div>

            <h4>Step 1.7.2. - Inpaintings</h4>
            <div>
                <p>
                    Inpainting starts with a original image and a boolean binary mask that keeps regions i want to
                    generate over, and that new image will be generated over the region where <code>m=1</code> and other
                    parts are kept as they have <code>m=0</code>. The model iteratively implements the diffusion loop
                    and obtains \(x_{t}\), we force it to have the same pixels as \(x_{\text{orig}}\) where
                    <code>m=0</code>, that is, by the formula: \[ x_t \leftarrow \textbf{m}x_t +
                    (1-\textbf{m})\text{forward}(x_{\text{orig}}, t) \], and we get the results shown above (I intended
                    to replace and inpaint the buildings in the background of the Campanile, as shown).
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/clean.png" alt="clean original image" class="small-im">
                        <p>
                            Clean Original Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/mask.png" alt="mask" class="small-im">
                        <p>
                            Mask
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/to-replace.png" alt="regions to replace" class="small-im">
                        <p>
                            To Replace (Inpaint Over)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/inpainted.png" alt="inpaint result" class="small-im">
                        <p>
                            Inpaint Result
                        </p>
                    </div>
                </div>
            </div>

            <div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/sf*.png" alt="clean original image" class="small-im">
                        <p>
                            Clean Original Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf-mask.png" alt="mask" class="small-im">
                        <p>
                            Mask
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf-to-replace.png" alt="regions to replace" class="small-im">
                        <p>
                            To Replace (Inpaint Over)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/sf-inpainted.png" alt="inpaint result" class="small-im">
                        <p>
                            Inpaint Result
                        </p>
                    </div>
                </div>
            </div>

            <div>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/deer*.png" alt="clean original image" class="small-im">
                        <p>
                            Clean Original Image
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dr-mask.png" alt="mask" class="small-im">
                        <p>
                            Mask
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dr-to-replace.png" alt="regions to replace" class="small-im">
                        <p>
                            To Replace (Inpaint Over)
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/dr-inpainted.png" alt="inpaint result" class="small-im">
                        <p>
                            Inpaint Result
                        </p>
                    </div>
                </div>
            </div>

            <h4>Step 1.7.3. - Text-Conditional Image-to-image Translation</h4>
            <div>
                <p>
                    Now we can change the prompt from "a high quality photo" to another one in the prompt dictionary to
                    guide the projection down a path aligning with the text prompt corresponding features, and below are
                    the results:
                </p>
            </div>
            <div class="gallery-row">
                <div class="image">
                    <img src="media/camp-1.png" alt="SDEdit of Campanile with i_start=1" class="small-im">
                    <p>
                        SDEdit (<code>i_start=1</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/camp-3.png" alt="SDEdit of Campanile with i_start=3" class="small-im">
                    <p>
                        SDEdit (<code>i_start=3</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/camp-5.png" alt="SDEdit of Campanile with i_start=5" class="small-im">
                    <p>
                        SDEdit (<code>i_start=5</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/camp-7.png" alt="SDEdit of Campanile with i_start=7" class="small-im">
                    <p>
                        SDEdit (<code>i_start=7</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/camp-10.png" alt="SDEdit of Campanile with i_start=10" class="small-im">
                    <p>
                        SDEdit (<code>i_start=10</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/camp-20.png" alt="SDEdit of Campanile with i_start=20" class="small-im">
                    <p>
                        SDEdit (<code>i_start=20</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/clean.png" alt="clean original image" class="small-im">
                    <p>
                        Campanile Original Image
                    </p>
                </div>
            </div>

            <div class="gallery-row">
                <div class="image">
                    <img src="media/imim-1-1.png" alt="SDEdit of Arthur Sword with i_start=1" class="small-im">
                    <p>
                        SDEdit (<code>i_start=1</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-1-3.png" alt="SDEdit of Arthur Sword with i_start=3" class="small-im">
                    <p>
                        SDEdit (<code>i_start=3</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-1-5.png" alt="SDEdit of Arthur Sword with i_start=5" class="small-im">
                    <p>
                        SDEdit (<code>i_start=5</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-1-7.png" alt="SDEdit of Arthur Sword with i_start=7" class="small-im">
                    <p>
                        SDEdit (<code>i_start=7</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-1-10.png" alt="SDEdit of Arthur Sword with i_start=10" class="small-im">
                    <p>
                        SDEdit (<code>i_start=10</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-1-20.png" alt="SDEdit of Arthur Sword with i_start=20" class="small-im">
                    <p>
                        SDEdit (<code>i_start=20</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-1.png" alt="clean original image" class="small-im">
                    <p>
                        Arthur Sword Original Image
                    </p>
                </div>
            </div>

            <div class="gallery-row">
                <div class="image">
                    <img src="media/imim-2-1.png" alt="SDEdit of Whale with i_start=1" class="small-im">
                    <p>
                        SDEdit (<code>i_start=1</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-2-3.png" alt="SDEdit of Whale with i_start=3" class="small-im">
                    <p>
                        SDEdit (<code>i_start=3</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-2-5.png" alt="SDEdit of Whale with i_start=5" class="small-im">
                    <p>
                        SDEdit (<code>i_start=5</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-2-7.png" alt="SDEdit of Whale with i_start=7" class="small-im">
                    <p>
                        SDEdit (<code>i_start=7</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-2-10.png" alt="SDEdit of Whale with i_start=10" class="small-im">
                    <p>
                        SDEdit (<code>i_start=10</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-2-20.png" alt="SDEdit of Whale with i_start=20" class="small-im">
                    <p>
                        SDEdit (<code>i_start=20</code>)
                    </p>
                </div>
                <div class="image">
                    <img src="media/imim-2.png" alt="clean original image" class="small-im">
                    <p>
                        Whale Original Image
                    </p>
                </div>
            </div>

            <h3>Step 1.8 - Visual Anagrams</h3>
            <div>
                <p>
                    To implement optical illusion generation, I denoised the image \(x_t\) with one prompt to calculate
                    \(\epsilon_1\ = \text{UNet}(x_t, t, p_1) \), but also flip the image \(x_t\) vertically and denoised
                    it with a another prompt to
                    calculate
                    \(\epsilon_2\ = \text{flip}(\text{UNet}(\text{flip}(x_t), t, p_2)) \) for noise approximations. And
                    we
                    can get the eventual noise by calculating the
                    average, but since
                    \(\epsilon_2\) if calculated for the flipped image, then we flip back the \(\epsilon_2\) for teh
                    averaging \( \frac{\epsilon_1 + \epsilon_2}{2} \).
                </p>
                <p>
                    I generated teh anagrams results shown below:
                </p>
                <p>
                    Combination from an oil painting of an old man & an oil painting of people around a campfire
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/oldman-1.png" alt="Anagrams of Oldman" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/oldman-2.png" alt="Anagrams of Oldman" class="small-im">
                    </div>
                </div>
                <p>
                    Combination from a photo of the amalfi cost & a lithograph of waterfalls
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/amalfi-1.png" alt="Anagrams of Amalfi" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/amalfi-2.png" alt="Anagrams of Amalfi" class="small-im">
                    </div>
                </div>
                <p>
                    Combination from a lithograph of a skull & an oil painting of a snowy mountain village
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/snowskull-1.png" alt="Anagrams of Skull" class="small-im">
                    </div>
                    <div class="image">
                        <img src="media/snowskull-2.png" alt="Anagrams of Skull" class="small-im">
                    </div>
                </div>
            </div>

            <h3>Step 1.9 - Hybrid Images</h3>
            <div>
                <p>
                    Use difussion models to hybridize images looking like one thing close up and another thing far away
                    (simulated by blurring with Gaussian).
                </p>
                <p>
                    This is achieved by the noise estimate from 2 different prompts, similar to the previous part, and
                    combine the low frequencies of one noise with the high frequencies of the other.
                </p>
            </div>
            <p>
                Hybrids of Skull & Waterfall
            </p>
            <div class="gallery-row">
                <div class="image">
                    <img src="media/skel-waterfall-C.png" alt="Hybrids of Skull & Waterfall" class="small-im">
                </div>
                <div class="image">
                    <img src="media/skel-waterfall-F.png" alt="Hybrids of Skull & Waterfall" class="small-im">
                </div>
            </div>
            <p>
                Hybrids of Rocket and Pencil
            </p>
            <div class="gallery-row">
                <div class="image">
                    <img src="media/rocket-pencil-C.png" alt="Hybrids of Rocket and Pencil" class="small-im">
                </div>
                <div class="image">
                    <img src="media/rocket-pencil-F.png" alt="Hybrids of Rocket and Pencil" class="small-im">
                </div>
            </div>
            <p>
                Hybrids of Hipster Barrista and Amalfi Coast
            </p>
            <div class="gallery-row">
                <div class="image">
                    <img src="media/hipster-amalfi-C.png" alt="Hybrids of Hipster Barrista and Amalfi Coast"
                        class="small-im">
                </div>
                <div class="image">
                    <img src="media/hipster-amalfi-F.png" alt="Hybrids of Hipster Barrista and Amalfi Coast"
                        class="small-im">
                </div>
            </div>
        </div>


        <div>
            <p>. </p>
            <p>. </p>
            <p>. </p>
            <p>. </p>
        </div>




        <div class="container">
            <h1>Part B: Feature Matching for Autostitching</h1>
            <div>
                <p>
                    This part of the project I trained a diffusion model on MNIST dataset to generate images of MNIST
                    digits and achieved by training UNet to do single-step denoising and train the UNet to ietratively
                    denoise by adding time conditioning and class conditioning to reverse the effects of noise on image
                    data.
                </p>
            </div>
            <h2>Part 1 - Training a Single-Step Denoising UNet</h2>
            <h3>Step 1.1 - Implementing the UNet</h3>
            <div>
                <p>
                    I start by building a simple one-step denoiser (UNet) tasked with mapping noisy images back to their
                    clean states and included downsampling and upsampling blocks with skip connections to preserve
                    crucial image features in trainng processes. The UNet input has is an imae and we add some level of
                    noise to it then output a prediction of what the denoised image would look like, and the MNIST
                    dataset has 28x28 pixel black and white images of digits. Below is the diagram illustrating the
                    workflow of the UNet.
                </p>
                <p>
                    The UNet was trained using L2 loss function minimizing difference b/w denoised output and original
                    image which prepares teh model for more complex operations involved varied degrees of noise.
                </p>
            </div>

            <h3>Step 1.2 - Using the UNet to Train a Denoiser</h3>
            <div>
                <p>
                    I then implemented the Feature Descriptor Extraction for each feature point found in the previous
                    part to facilitae accurate image matching. I 1st convert the input image to grayscale if it is not
                    already to simplify feature descriptor extraction by reducing data dimensionality and use corner
                    points identified from previous ANMS result as centers for feature descriptor extraction.
                </p>

                <div class="image">
                    <img src="media/unconditional_arch.png" alt="UNet Ark">
                </div>

                <p>
                    The denoiser \( D_{\theta}(z) \) aims to minimize L2 loss b/w denoised image & clean original image,
                    with the loss function as
                    \( L = \mathbb{E}_{z,x} \Vert D_{\theta}(z) - x \Vert^2 \) where \( \mathbb{E} \) is expectation
                    over dist. of clean images \(x\) and their corresponding noisy version \(z\).
                </p>
                <p>
                    Noisy training pairs \((z,x)\) were generated by applying random noise vector \( \epsilon \) scaled
                    by \(\sigma\) a predetermined noise level to clean images \(x\):
                    \( z = x + \sigma\epsilon \) where the formula was fundamental in simulating various noise to
                    enhance UNet robustness.
                </p>
                <p>
                    The UNet was adapted to predict the noise \(\epsilon\) which is added to the clean original image
                    effectively making the learning of the reverse of intial noise mapping process: \( L =
                    \mathbb{E}_{\epsilon,z} \Vert \epsilon_{\theta}(z) - \epsilon \Vert^2 \)
                </p>
                <p>
                    And this facilitaed diffusion as a schedule of noise levels being introduced, the model learned to
                    adjust predicted noise based on specific step in teh diffusion process, improving single-step
                    denoising, allowing the model to handle broader range of noise intensities effectively.
                </p>
                <p>
                    Below is the noises added iteratively over various sigma values (\([0.0, 0.2, 0.4, 0.5, 0.6, 0.8,
                    1.0]\)) for all the digits:
                </p>
                <div class="image">
                    <img src="media/noise_added.jpg" alt="Noises Added">
                </div>
                <p>
                    I run the model over several epochs of training, where under each we generate new noisy images to
                    ensure diverse range of challenges for the denoiser for training and I also chose to denoise noisy
                    MNIST digit \(z\) generated using teh above mentioned formula with \(\sigma=0.5\) on \(x\), and also
                    fine-tune the model by setting hidden dimensions \(D=128\), batch size of 256, over 5 epochs, and an
                    Adam optimizer using mean squared error as Loss function and a learning rate of \(1 \times
                    10^{-4}\), and teh result of the losses are recorded, as are the gradient descent steps we took, as
                    shown below.
                </p>
                <div class="image">
                    <img src="media/reg_loss_v_steps.jpg" alt="Regular Loss vs Steps Plot">
                </div>

                <p>
                    After specific training intervals where I chose 1st and 5th epochs, the denoised images were
                    visualized below. And we clearly see that the denoised images after epoch 5 are clearer and more
                    in-line with the original image, indicating more success in the denoising process with higher
                    epochs.
                </p>
                <div class="gallery-row">
                    <div class="image">
                        <img src="media/denoised_ims_after_epoch_1.jpg" alt="Denoised Images after Epoch 1">
                        <p>
                            Denoised Images after Epoch 1
                        </p>
                    </div>
                    <div class="image">
                        <img src="media/denoised_ims_after_epoch_5.jpg" alt="Denoised Images after Epoch 5">
                        <p>
                            Denoised Images after Epoch 5
                        </p>
                    </div>
                </div>

                <p>
                    After, I performed the denoising on sigma values that were not trained for before and performed the
                    denoising and got the following results, and we can see that the more noises there are, the harder
                    it is for us to restore it to original (for now).
                </p>
                <div class="image">
                    <img src="media/OOD_denoised_ims.jpg" alt="Out-of-Distribution">
                </div>
            </div>

            <p>. </p>

            <h2>Part 2 - Training a Diffusion Model</h2>
            <h3>Step 2.1 - Adding Time Conditioning to UNet</h3>
            <div>
                <p>
                    The UNet was conditioned on timestep \(t\) requiring me to modify the network to include timestep
                    embeddings so I can fully connect the layers (FCBlocks) that integrated the timestep information
                    into the network, allowing the model to adjust based on diffusion progress.
                </p>
                <p>
                    The UNet architecture is also modified so that it can condition our input on \(t\) by adding fully
                    connected blocks (FCBlocks) to it, as shown below (from project spec).
                </p>
                <div class="image">
                    <img src="media/time_conditional_arch.png" alt="Time-Cond UNet Ark">
                </div>
            </div>

            <h3>Step 2.2-2.3 - Training & Sampling from the UNet</h3>
            <p>
                And based on the following pseudocode from the spec:</p>
            <div class="image">
                <img src="media/algo1_t_only.png" alt="algo1_t_only">
            </div>
            <p>
                I defined the important parameters including <code>FCBlock</code> which is used to inject the
                timestep \(t\) info into the UNet which are normalized and passed through these blocks to modulate
                features throughout network layers. This allows prediction of noise \(\epsilon\) mapped into the
                original clean image and we do this successively and cumulatively so that we end up with an image of
                pure noise so generating a well-restored image \(x\) becomes possible through the reverse,
                iteratively and cumulatively denoising (gradient descent \( \nabla_\theta \|\epsilon -
                \tilde{\epsilon}\|^2 )\), as shown by the mathematical formula: \[x_t =
                \sqrt{\alpha_t}
                x_0 + \sqrt{1 - \alpha_t} \epsilon\].
            </p>
            <p>
                I start from \(x_0\) and for each timestep \(t \in \{0,1,\cdots,T\}\), noise is mapped and added to
                the previous image, and eventually generate a noisy image \(x_t\).
            </p>
            <p>
                And with the modification in-place, I train the new model with many fine-tuned parameters, including
                hidden dimensions \(D=64\), batch size of 128, over 20 epochs, and an
                Adam optimizer using mean squared error as Loss function and a learning rate of \(1 \times
                10^{-3}\), decaying as scheduled as specified by the parameter
                \(\gamma = 0.1^{(1/\text{number of epochs})} = 0.1^{\frac{1}{20}}\), and the result of the losses
                are recorded, as are the gradient descent steps we took, as shown below.
            </p>
            <div class="image">
                <img src="media/time_cond_loss_v_steps.jpg" alt="Time Conditioned Loss vs Steps Plot">
            </div>

            <p>
                Then I sample from the new model per the mathematical formula workflow as shown below.
            </p>
            <div class="image">
                <img src="media/algo2_t_only.png" alt="algo2_t_only">
            </div>
            <p>
                The process starts iwth a completely noised image \(z_T ~ N(0,I)\) that ensures it does not resemble the
                original data, and progressively start from \(t=T\) down to \(t=0\), apply the UNet model
                \(\epsilon_{\theta}\), then predicts the noise \(\epsilon\) that needs to be subtracted from current
                noisy image, so to denoise it through the new architecture to retrieve a clean (best-restored) image
                that resembles the original data. I also implemented the variance of the noise at each timestep
                \(\sigma(t)\) determining noise amount the model expects to eliminate.
            </p>
            <p>
                Then, like the previous part, I run the model over 20 epochs of training, and monitored the results at
                key epochs 1, 5, 10, 15, 20 to assess improvements and refine the denoising abilities and at each epoch,
                fresh batches of noisy MNISt digits were selected using the formula \(z = x+0.5\epsilon\), giving the
                model slight difficulties to overcome through robust learning, and the results are displayed below.
            </p>
            <script>
                function restartGif(img) {
                    var currentSrc = img.src;
                    img.src = '';
                    img.src = currentSrc;
                }
            </script>

            <div class="gallery-row">
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_1(time-cond).gif" alt="ddpm_denoise_epoch_1(time-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 1</p>
                </div>
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_5(time-cond).gif" alt="ddpm_denoise_epoch_5(time-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 5</p>
                </div>
            </div>
            <div class="gallery-row">
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_10(time-cond).gif" alt="ddpm_denoise_epoch_10(time-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 10</p>
                </div>
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_15(time-cond).gif" alt="ddpm_denoise_epoch_15(time-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 15</p>
                </div>
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_20(time-cond).gif" alt="ddpm_denoise_epoch_20(time-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 20</p>
                </div>
            </div>

            <h3>Step 2.4 - Adding Class-Conditioning to UNet</h3>
            <div>
                <p>
                    The UNet was conditioned not only on timestep \(t\) but now also on the class labels of the images,
                    which is especially useful for datasets with distinct categories like MNIST \( (0, ..., 9) \).
                </p>
                <p>
                    Two more FCBlocks are added to the UNet architecture to include class information alongside
                    timesteps and by using one-hot encoding to integrate class labels into the diffusion process to
                    guide the denoisingsteps more accurately.
                </p>
                <p>
                    Dropout is also implemented to prevent model from overly relying on class info, by using where the
                    class embedding is occasionally set to 0 during training, simulating scenarios where class info
                    might be ambiguous, approximating to 10% of the time to drop class conditioning.
                </p>
                <p>
                    The algorithm is similar to the one before but with the additional one-hot encoding included, as
                    shown below:
                </p>
                <div class="image">
                    <img src="media/algo3_c.png" alt="algo3_c">
                </div>
                <p>
                    The loss is calculated mostly similar to the previous part. It is adapted to include class info but
                    also time conditioning, enhancing teh model's specificity in handling different categories of input
                    data.
                </p>
                <p>
                    The new element in the loss fuction also integrates a class-conditioned vector, combining time
                    conditioning, and thi saddition allows noise prediction to be based on diffusion timestep and class
                    of digit, expressed by \(L = \mathbb{E}_{\epsilon, z, t, c} \Vert \epsilon_{\theta}(z, t, c) -
                    \epsilon \Vert^2 \), where \(c\) represents the class of the digit. And with the implementation,
                    below is the loss versus gradient descent steps plot.
                </p>
                <div class="image">
                    <img src="media/class_cond_loss_v_steps.jpg" alt="Class Conditioned Loss vs Steps Plot">
                </div>
            </div>

            <h3>Step 2.5 - Sampling from the Class-Conditioned UNet</h3>
            <p>
                Then I sample from the new model per the mathematical formula workflow as shown below.
            </p>
            <div class="image">
                <img src="media/algo4_c.png" alt="algo4_c">
            </div>
            <p>
                The process is mostly similar to the previous part, but with the added one-hot vector for class labels
                CFG scale (\(\gamma\)), which adjusts noise prediction by blending unconditioned and class-conditioned
                predictions (\(\epsilon = \epsilon_u + \gamma(\epsilon_c - \epsilon_u)\)), allowing model to generate
                images more aligned with teh specific digit classes.
            </p>
            <p>
                Then, like the previous part, I run the model over 20 epochs of training, and monitored the results at
                key epochs 1, 5, 10, 15, 20 to assess improvements and refine the denoising abilities and at each epoch,
                and the results are displayed below. And we see that because we have conditioned on classes, the digits
                are all selected in order, unlike teh part before which is not.
            </p>
            <div class="gallery-row">
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_1(class-cond).gif" alt="ddpm_denoise_epoch_1(class-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 1</p>
                </div>
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_5(class-cond).gif" alt="ddpm_denoise_epoch_5(class-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 5</p>
                </div>
            </div>
            <div class="gallery-row">
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_10(class-cond).gif" alt="ddpm_denoise_epoch_10(class-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 10</p>
                </div>
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_15(class-cond).gif" alt="ddpm_denoise_epoch_15(class-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 15</p>
                </div>
                <div class="cond-gif">
                    <img src="media/ddpm_denoise_epoch_20(class-cond).gif" alt="ddpm_denoise_epoch_20(class-cond).gif"
                        onmouseover="restartGif(this)">
                    <p>Epoch 20</p>
                </div>
            </div>
            <h2>Summary</h2>
            <p>
                I learned many things about diffusion models and I really enjoyed drawing the images to see how the
                algorithm be able to recognize the object I wanted, and I also liked how the different prompts and their
                combinations create various interesting pictures. I also enjoyed implementing and filling in the model
                to see how MNIST digits are denoised to restore to resemble original clean images.
            </p>
        </div>

    </section>
</body>

</html>
